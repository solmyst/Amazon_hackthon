{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart Product Pricing Challenge - Experimentation Notebook\n",
    "\n",
    "This notebook helps you explore the data and test different approaches for the pricing challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "# Set style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "DATASET_FOLDER = 'dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Explore Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample data for exploration\n",
    "sample_test = pd.read_csv(os.path.join(DATASET_FOLDER, 'sample_test.csv'))\n",
    "sample_out = pd.read_csv(os.path.join(DATASET_FOLDER, 'sample_test_out.csv'))\n",
    "\n",
    "print(f\"Sample test shape: {sample_test.shape}\")\n",
    "print(f\"Sample output shape: {sample_out.shape}\")\n",
    "\n",
    "# Merge for analysis\n",
    "sample_data = sample_test.merge(sample_out, on='sample_id')\n",
    "print(f\"Merged sample data shape: {sample_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Price Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price statistics\n",
    "print(\"Price Statistics:\")\n",
    "print(sample_data['price'].describe())\n",
    "\n",
    "# Plot price distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(sample_data['price'], bins=30, alpha=0.7, edgecolor='black')\n",
    "axes[0].set_title('Price Distribution')\n",
    "axes[0].set_xlabel('Price ($)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(sample_data['price'])\n",
    "axes[1].set_title('Price Box Plot')\n",
    "axes[1].set_ylabel('Price ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_stats(text):\n",
    "    \"\"\"Extract basic text statistics\"\"\"\n",
    "    text = str(text)\n",
    "    return {\n",
    "        'length': len(text),\n",
    "        'word_count': len(text.split()),\n",
    "        'number_count': len(re.findall(r'\\d+\\.?\\d*', text))\n",
    "    }\n",
    "\n",
    "# Extract text features\n",
    "text_stats = sample_data['catalog_content'].apply(extract_text_stats)\n",
    "text_df = pd.DataFrame(text_stats.tolist())\n",
    "\n",
    "# Add to sample data\n",
    "sample_analysis = pd.concat([sample_data, text_df], axis=1)\n",
    "\n",
    "print(\"Text Statistics:\")\n",
    "print(text_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with price\n",
    "correlations = sample_analysis[['price', 'length', 'word_count', 'number_count']].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlations, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlations with Price')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelations with price:\")\n",
    "print(correlations['price'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Product Category Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_product(text):\n",
    "    \"\"\"Simple product categorization\"\"\"\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    if any(word in text for word in ['food', 'snack', 'candy', 'sauce', 'spice']):\n",
    "        return 'Food'\n",
    "    elif any(word in text for word in ['cosmetic', 'beauty', 'lip', 'lotion']):\n",
    "        return 'Beauty'\n",
    "    elif any(word in text for word in ['cleaning', 'dish', 'soap']):\n",
    "        return 'Cleaning'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Categorize products\n",
    "sample_analysis['category'] = sample_analysis['catalog_content'].apply(categorize_product)\n",
    "\n",
    "# Category distribution\n",
    "category_counts = sample_analysis['category'].value_counts()\n",
    "print(\"Category Distribution:\")\n",
    "print(category_counts)\n",
    "\n",
    "# Price by category\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=sample_analysis, x='category', y='price')\n",
    "plt.title('Price Distribution by Category')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Average price by category\n",
    "avg_price_by_category = sample_analysis.groupby('category')['price'].mean().sort_values(ascending=False)\n",
    "print(\"\\nAverage Price by Category:\")\n",
    "print(avg_price_by_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quantity and Unit Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_quantities(text):\n",
    "    \"\"\"Extract quantity information\"\"\"\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Find numbers\n",
    "    numbers = re.findall(r'\\d+\\.?\\d*', text)\n",
    "    \n",
    "    # Check for units\n",
    "    units = {\n",
    "        'oz': 'oz' in text or 'ounce' in text,\n",
    "        'lb': 'lb' in text or 'pound' in text,\n",
    "        'count': 'count' in text or 'pack' in text,\n",
    "        'fl_oz': 'fl oz' in text\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'max_number': max([float(x) for x in numbers]) if numbers else 0,\n",
    "        **units\n",
    "    }\n",
    "\n",
    "# Extract quantity features\n",
    "quantity_features = sample_analysis['catalog_content'].apply(extract_quantities)\n",
    "quantity_df = pd.DataFrame(quantity_features.tolist())\n",
    "\n",
    "# Add to analysis\n",
    "sample_analysis = pd.concat([sample_analysis, quantity_df], axis=1)\n",
    "\n",
    "print(\"Quantity Analysis:\")\n",
    "print(f\"Products with oz: {quantity_df['oz'].sum()}\")\n",
    "print(f\"Products with count: {quantity_df['count'].sum()}\")\n",
    "print(f\"Products with fl_oz: {quantity_df['fl_oz'].sum()}\")\n",
    "\n",
    "# Price vs max number\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(sample_analysis['max_number'], sample_analysis['price'], alpha=0.6)\n",
    "plt.xlabel('Max Number in Description')\n",
    "plt.ylabel('Price ($)')\n",
    "plt.title('Price vs Maximum Number in Description')\n",
    "plt.show()\n",
    "\n",
    "# Correlation\n",
    "corr = sample_analysis['max_number'].corr(sample_analysis['price'])\n",
    "print(f\"\\nCorrelation between max_number and price: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Quick Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the quick solution on sample data\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def quick_test():\n",
    "    \"\"\"Quick test on sample data\"\"\"\n",
    "    \n",
    "    # Use sample data as both train and test for demonstration\n",
    "    X = sample_analysis[['length', 'word_count', 'number_count', 'max_number']]\n",
    "    y = sample_analysis['price']\n",
    "    \n",
    "    # Simple train-test split\n",
    "    split_idx = int(0.7 * len(X))\n",
    "    X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "    y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluate\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    \n",
    "    print(f\"Quick Test Results:\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    \n",
    "    # Calculate SMAPE\n",
    "    smape = np.mean(np.abs(predictions - y_test) / ((np.abs(y_test) + np.abs(predictions)) / 2)) * 100\n",
    "    print(f\"SMAPE: {smape:.2f}%\")\n",
    "    \n",
    "    return predictions, y_test\n",
    "\n",
    "pred, actual = quick_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions vs actual\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(actual, pred, alpha=0.6)\n",
    "plt.plot([actual.min(), actual.max()], [actual.min(), actual.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Price ($)')\n",
    "plt.ylabel('Predicted Price ($)')\n",
    "plt.title('Predicted vs Actual Prices')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps\n",
    "\n",
    "Based on this analysis, consider:\n",
    "\n",
    "1. **Feature Engineering**: Extract more sophisticated features from text\n",
    "2. **Image Features**: Add visual features using pre-trained models\n",
    "3. **Advanced Models**: Try XGBoost, neural networks, or ensemble methods\n",
    "4. **Text Processing**: Use more advanced NLP techniques\n",
    "5. **Cross-validation**: Implement proper validation strategy\n",
    "\n",
    "Run the full solution with: `python solution.py` or `python quick_solution.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}